# Importar las librer√≠as necesarias
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# üìù Contexto del Proyecto
st.header("üìù Contexto del Proyecto")
st.markdown("""
Este proyecto utiliza datos del **[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29)**, 
un recurso p√∫blico ampliamente utilizado en investigaciones de ciencia de datos.  
El dataset fue recopilado originalmente por el Dr. William H. Wolberg, en el Hospital de la Universidad de Wisconsin, y contiene mediciones relevantes obtenidas de im√°genes digitalizadas de tumores mamarios. Estas mediciones incluyen caracter√≠sticas como el tama√±o, la forma y la textura de los tumores.

### Objetivo:
- Desarrollar modelos predictivos usando t√©cnicas de **Machine Learning** que clasifiquen tumores en **benignos** o **malignos**.
- Identificar caracter√≠sticas clave que contribuyan significativamente al diagn√≥stico.

**Nota Importante:** Este proyecto se realiza con fines **educativos** y forma parte de mi portafolio como estudiante de ciencia de datos. No est√° dise√±ado para reemplazar el juicio m√©dico profesional.
""")

# üéóÔ∏è Introducci√≥n del Proyecto
st.title("üéóÔ∏è Diagn√≥stico de C√°ncer de Mama con Machine Learning üéóÔ∏è")
st.markdown("""
Este proyecto demuestra c√≥mo las t√©cnicas de **Machine Learning** pueden asistir en la detecci√≥n y diagn√≥stico temprano de tumores mamarios, clasific√°ndolos en **benignos** o **malignos**.  
**Nota Importante:** Este trabajo ha sido realizado con fines acad√©micos y forma parte de mi portafolio.  
**Autora:** Cristina Puertas Camarero  
""")

# Logo (centrado y tama√±o ajustado)
st.markdown(
    """
    <div style="text-align: center;">
        <img src="logo_cancer_mama.png" alt="Logo C√°ncer de Mama" style="width: 120px;"/>
    </div>
    """,
    unsafe_allow_html=True
)

# üìÇ Carga del Dataset
st.header("üìÇ Carga del Dataset")
try:
    # Ruta al dataset
    dataset_path = r"C:\Users\Propietario\Documents\IronHack 01\Machine_Learning_for_Breast_Cancer_Diagnostics\Machine_Learning_for_Breast_Cancer_Diagnostics\datos\4_dataset_sin_correlaciones_altas.csv"

    # Cargar dataset
    df = pd.read_csv(dataset_path)
    st.success("Dataset cargado exitosamente. Aqu√≠ est√°n las primeras filas:")
    st.dataframe(df.head())  # Mostrar las primeras filas del dataset

except Exception as e:
    st.error("Hubo un error al cargar el dataset. Por favor verifica la ruta y el archivo.")
    st.text(f"Detalles del error: {e}")

# üìä An√°lisis Exploratorio de los Datos
st.header("üìä An√°lisis Exploratorio de los Datos")

# Distribuci√≥n de tumores
st.subheader("üéóÔ∏è Distribuci√≥n de Tumores")
st.markdown("""
Analizar cu√°ntos tumores son **benignos** y cu√°ntos **malignos** nos permite entender si el dataset est√° equilibrado, 
lo cual es crucial para el entrenamiento de los modelos.
""")
fig1, ax1 = plt.subplots()
sns.countplot(data=df, x="Diagnosis", palette="Purples", ax=ax1)
ax1.set_title("Distribuci√≥n de Tumores", fontsize=16)
ax1.set_xlabel("Tipo de Tumor", fontsize=12)
ax1.set_ylabel("Cantidad", fontsize=12)
st.pyplot(fig1)

# Relaci√≥n entre caracter√≠sticas clave
st.subheader("üìà Relaci√≥n entre Caracter√≠sticas Clave")
st.markdown("""
Exploramos la relaci√≥n entre caracter√≠sticas importantes como `Mean_Radius` y `Mean_Concavity`, 
las cuales son esenciales para distinguir entre tumores benignos y malignos.
""")
fig2, ax2 = plt.subplots()
sns.scatterplot(data=df, x="Mean_Radius", y="Mean_Concavity", hue="Diagnosis", palette="coolwarm", ax=ax2)
ax2.set_title("Relaci√≥n entre `Mean_Radius` y `Mean_Concavity`", fontsize=16)
ax2.set_xlabel("Mean Radius", fontsize=12)
ax2.set_ylabel("Mean Concavity", fontsize=12)
st.pyplot(fig2)

# Histograma de una caracter√≠stica clave
st.subheader("üìä Distribuci√≥n de `Mean_Radius`")
st.markdown("""
El histograma muestra c√≥mo el `Mean_Radius` (tama√±o promedio del tumor) var√≠a entre tumores benignos y malignos.
""")
fig3, ax3 = plt.subplots()
sns.histplot(data=df, x="Mean_Radius", hue="Diagnosis", multiple="stack", palette="Purples", kde=True, ax=ax3)
ax3.set_title("Distribuci√≥n de `Mean_Radius` por Tipo de Tumor", fontsize=16)
ax3.set_xlabel("Mean Radius", fontsize=12)
ax3.set_ylabel("Frecuencia", fontsize=12)
st.pyplot(fig3)

# üîç Exploraci√≥n Interactiva
st.subheader("üîç Exploraci√≥n Interactiva de las Caracter√≠sticas")
selected_feature_hist = st.selectbox(
    "Selecciona una caracter√≠stica para ver su distribuci√≥n (Histograma):", 
    df.columns.drop("Diagnosis")
)
selected_feature_x = st.selectbox(
    "Selecciona la caracter√≠stica X (Gr√°fico de Dispersi√≥n):", 
    df.columns.drop("Diagnosis")
)
selected_feature_y = st.selectbox(
    "Selecciona la caracter√≠stica Y (Gr√°fico de Dispersi√≥n):", 
    df.columns.drop("Diagnosis")
)

# Histograma interactivo
st.subheader(f"üìä Distribuci√≥n de `{selected_feature_hist}`")
fig_hist, ax_hist = plt.subplots()
sns.histplot(data=df, x=selected_feature_hist, hue="Diagnosis", multiple="stack", palette="Purples", kde=True, ax=ax_hist)
ax_hist.set_title(f"Distribuci√≥n de `{selected_feature_hist}` por Tipo de Tumor", fontsize=16)
ax_hist.set_xlabel(selected_feature_hist, fontsize=12)
ax_hist.set_ylabel("Frecuencia", fontsize=12)
st.pyplot(fig_hist)

# Gr√°fico de dispersi√≥n interactivo
st.subheader(f"üìà Relaci√≥n entre `{selected_feature_x}` y `{selected_feature_y}`")
fig_scatter, ax_scatter = plt.subplots()
sns.scatterplot(data=df, x=selected_feature_x, y=selected_feature_y, hue="Diagnosis", palette="coolwarm", ax=ax_scatter)
ax_scatter.set_title(f"Relaci√≥n entre `{selected_feature_x}` y `{selected_feature_y}`", fontsize=16)
ax_scatter.set_xlabel(selected_feature_x, fontsize=12)
ax_scatter.set_ylabel(selected_feature_y, fontsize=12)
st.pyplot(fig_scatter)

# üìä M√©tricas del Modelo
st.header("üìä Resultados del Modelo")
metrics_data = {
    "Modelo": ["Random Forest", "Logistic Regression"],
    "Precisi√≥n (%)": [95.38, 92.52],
    "AUC": [0.99, 0.99],
    "Recall Maligno (%)": [95.0, 92.0]
}
metrics_df = pd.DataFrame(metrics_data)
st.dataframe(metrics_df)
st.markdown("""
- **Accuracy (Precisi√≥n):** Indica qu√© porcentaje de las predicciones fueron correctas.
- **AUC:** Mide la capacidad del modelo para distinguir entre clases.
- **Recall Maligno:** Prioriza identificar correctamente tumores malignos, reduciendo falsos negativos.
""")

# üåü Importancia de las Caracter√≠sticas
st.subheader("üåü Importancia de las Caracter√≠sticas")
feature_importances = {
    "Caracter√≠sticas": [
        "Mean_Radius", "Worst_Concavity", "Mean_Concavity", 
        "SE_Radius", "Worst_Compactness", "Mean_Texture", 
        "Mean_Compactness", "Worst_Symmetry", "SE_Concavity", 
        "Worst_Smoothness"
    ],
    "Importancia": [0.202525, 0.170028, 0.134734, 0.087134, 0.069220, 0.049379, 0.049048, 0.031817, 0.028763, 0.024632]
}
importances_df = pd.DataFrame(feature_importances)
fig_features, ax_features = plt.subplots(figsize=(10, 6))
sns.barplot(data=importances_df, x="Importancia", y="Caracter√≠sticas", palette="Purples", ax=ax_features)
ax_features.set_title("Top 10 Caracter√≠sticas M√°s Importantes", fontsize=16)
ax_features.set_xlabel("Importancia Relativa", fontsize=12)
ax_features.set_ylabel("Caracter√≠sticas", fontsize=12)
st.pyplot(fig_features)

# üõ†Ô∏è Pasos Realizados en el Proyecto
st.header("üõ†Ô∏è Pasos Realizados en el Proyecto")
st.markdown("""
A continuaci√≥n, se describen los pasos que seguimos para desarrollar este proyecto y llegar a las conclusiones finales:

### 1Ô∏è‚É£ Exploraci√≥n y Visualizaci√≥n de los Datos:
- Cargamos el dataset y examinamos su estructura para comprender las variables disponibles.
- Visualizamos la distribuci√≥n de tumores benignos y malignos, as√≠ como relaciones clave entre variables, utilizando gr√°ficos como histogramas y gr√°ficos de dispersi√≥n.
- Identificamos correlaciones entre caracter√≠sticas, destacando variables que pod√≠an ser redundantes o no relevantes.

### 2Ô∏è‚É£ Limpieza y Preprocesamiento:
- Eliminamos columnas irrelevantes (como identificadores) y aquellas con alta correlaci√≥n para evitar multicolinealidad.
- Transformamos variables categ√≥ricas en formato num√©rico (por ejemplo, la columna de diagn√≥stico).
- Normalizamos las caracter√≠sticas para facilitar el entrenamiento de los modelos.

### 3Ô∏è‚É£ An√°lisis Exploratorio de Datos (EDA):
- Detectamos qu√© caracter√≠sticas presentaban las mayores diferencias entre tumores benignos y malignos.
- Algunas caracter√≠sticas clave identificadas fueron:
  - **`Mean_Radius` (Radio Promedio):** Tama√±o promedio del tumor.
  - **`Worst_Concavity` (Mayor Concavidad):** Indicador de irregularidades en los contornos de los tumores.

### 4Ô∏è‚É£ Modelado Predictivo:
- Entrenamos y evaluamos diferentes modelos de **Machine Learning**, incluyendo:
  - **Random Forest:** Un modelo basado en m√∫ltiples √°rboles de decisi√≥n, ideal para identificar patrones complejos.
  - **Logistic Regression:** Un modelo m√°s sencillo pero interpretable, √∫til en contextos m√©dicos.
  - **Support Vector Machines (SVM):** Captura relaciones no lineales entre las caracter√≠sticas.
- Usamos **cross-validation** para evaluar el rendimiento de los modelos en datos desconocidos.

### 5Ô∏è‚É£ Optimizaci√≥n de Hiperpar√°metros:
- Ajustamos hiperpar√°metros clave de los modelos usando **GridSearchCV**, probando m√∫ltiples combinaciones para encontrar la configuraci√≥n √≥ptima.
- Por ejemplo, en **Random Forest**:
  - **N√∫mero de √°rboles:** 100
  - **M√°xima profundidad:** Sin restricciones (para permitir una mayor complejidad).
  - **Criterio de divisi√≥n:** Entrop√≠a.

### 6Ô∏è‚É£ Comparaci√≥n de Modelos:
- Comparamos los modelos utilizando m√©tricas clave como:
  - **Accuracy (Precisi√≥n):** Qu√© porcentaje de predicciones fueron correctas.
  - **AUC (√Årea Bajo la Curva ROC):** Qu√© tan bien separan los modelos entre tumores benignos y malignos.
  - **Recall:** Qu√© tan bien identifican los modelos los tumores malignos.
- **Resultados Destacados:**
  - El **Random Forest** fue el modelo m√°s robusto, con un **Accuracy** del **95.38%** y un **AUC** de **0.99**.
  - Aunque la **Logistic Regression** tambi√©n alcanz√≥ un AUC de **0.99**, tuvo un rendimiento ligeramente inferior en t√©rminos de precisi√≥n general.

### 7Ô∏è‚É£ Conclusiones:
- **Random Forest** se destac√≥ como el modelo m√°s efectivo y robusto.
- Las caracter√≠sticas m√°s importantes para el modelo incluyen `Mean_Radius` y `Worst_Concavity`.
- Este an√°lisis demuestra c√≥mo las herramientas de Machine Learning pueden complementar el juicio cl√≠nico en el diagn√≥stico temprano de c√°ncer de mama.
""")


# ‚ú® Conclusiones
st.header("‚ú® Conclusiones")
st.markdown("""
Este proyecto destaca c√≥mo las t√©cnicas de **Machine Learning**, como **Random Forest**, pueden ayudar en el diagn√≥stico temprano de tumores.  
**Resumen del Proceso:**
- Analizamos los datos para identificar caracter√≠sticas clave.
- Entrenamos modelos como **Random Forest** y **Logistic Regression** para predecir tumores.
- Evaluamos los modelos con m√©tricas como **Accuracy**, **AUC** y **Recall Maligno**.

**Resultados Clave:**
- **Random Forest** alcanz√≥ una precisi√≥n del **95.38%** y un AUC de **0.99**.
- Las caracter√≠sticas m√°s importantes incluyen `Mean_Radius` y `Worst_Concavity`.

üíñ **Gracias por explorar este proyecto educativo, creado con fines acad√©micos y para mi portafolio. El c√°ncer de mama es un tema de gran sensibilidad. Sigamos innovando para marcar una diferencia positiva.**
""")

