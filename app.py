# Importar las librer√≠as necesarias
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib

# Configurar el backend de Matplotlib recomendado para Streamlit
matplotlib.use('Agg')

# Configuraci√≥n inicial de la aplicaci√≥n
st.set_page_config(page_title="Diagn√≥stico de C√°ncer de Mama", layout="wide")

# Crear una barra lateral para la navegaci√≥n entre pantallas
page = st.sidebar.selectbox(
    "Navegaci√≥n",
    ["Portada", "Resultados y An√°lisis", "Predicciones Interactivas"]
)

# üåü Pantalla 1: Portada
if page == "Portada":
    st.title("üéóÔ∏è Bienvenidos al Proyecto de Diagn√≥stico de C√°ncer de Mama")
    st.markdown("""
    Este proyecto explora c√≥mo las t√©cnicas de **Machine Learning** pueden asistir en el diagn√≥stico temprano de tumores mamarios, clasific√°ndolos en **benignos** o **malignos**.
    El c√°ncer de mama es uno de los desaf√≠os m√°s importantes en el √°mbito de la salud p√∫blica, siendo una de las principales causas de mortalidad en mujeres. Seg√∫n la Organizaci√≥n Mundial de la Salud (OMS), el diagn√≥stico temprano es clave para aumentar las probabilidades de supervivencia.
    """)
    st.image("cancer.jpg", caption="Lucha contra el c√°ncer de mama", use_container_width=True)
    st.markdown("""
    ### Contexto del Proyecto:
    - **Datos:** Extra√≠dos del [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29).
    - **Prop√≥sito:** Crear un modelo predictivo y analizar caracter√≠sticas clave relacionadas con el diagn√≥stico.

    Este trabajo es exclusivamente **acad√©mico** y forma parte de mi portafolio como estudiante de ciencia de datos.  
    **Autora:** Cristina Puertas Camarero
    """)

# üìä Pantalla 2: Resultados y An√°lisis
elif page == "Resultados y An√°lisis":
    st.title("üìä Resultados y An√°lisis del Proyecto")
    st.markdown("""
    En esta secci√≥n exploraremos las visualizaciones, el an√°lisis de caracter√≠sticas y las m√©tricas de los modelos utilizados en este estudio. Tambi√©n explicaremos c√≥mo hemos llegado a nuestras conclusiones.  
    """)

    # üìÇ Carga del Dataset
    st.header("üìÇ Carga del Dataset")
    try:
        # Ruta al dataset
        dataset_path = r"C:\Users\Propietario\Documents\IronHack 01\Machine_Learning_for_Breast_Cancer_Diagnostics\Machine_Learning_for_Breast_Cancer_Diagnostics\datos\4_dataset_sin_correlaciones_altas.csv"

        # Cargar dataset
        df = pd.read_csv(dataset_path)
        st.success("Dataset cargado exitosamente. Aqu√≠ est√°n las primeras filas:")
        st.dataframe(df.head())  # Mostrar las primeras filas del dataset

    except Exception as e:
        st.error("Hubo un error al cargar el dataset. Por favor verifica la ruta y el archivo.")
        st.text(f"Detalles del error: {e}")
        st.stop()

    # üõ†Ô∏è Pasos del Proyecto
    st.header("üõ†Ô∏è Pasos del Proyecto")
    st.markdown("""
    ### 1Ô∏è‚É£ Exploraci√≥n y Visualizaci√≥n de los Datos:
    - Analizamos la estructura del dataset y visualizamos distribuciones clave.
    - Identificamos correlaciones y posibles redundancias entre caracter√≠sticas.

    ### 2Ô∏è‚É£ Limpieza y Preprocesamiento:
    - Eliminamos columnas irrelevantes y aquellas con alta correlaci√≥n.
    - Transformamos variables categ√≥ricas en formato num√©rico.
    - Normalizamos caracter√≠sticas para un mejor rendimiento del modelo.

    ### 3Ô∏è‚É£ Modelado Predictivo:
    - Probamos modelos como **Random Forest**, **Logistic Regression** y **Support Vector Machines (SVM)**.
    - Usamos **GridSearchCV** para ajustar hiperpar√°metros clave.

    ### 4Ô∏è‚É£ Evaluaci√≥n y Comparaci√≥n de Modelos:
    - Comparamos m√©tricas como **Accuracy**, **AUC** y **Recall Maligno**.
    - **Resultados Destacados:**
      - El **Random Forest** fue el modelo m√°s efectivo, con un **Accuracy** del **95.38%** y un **AUC** de **0.99**.
    """)

    # üìä M√©tricas del Modelo
    st.subheader("üìä Resultados del Modelo")
    metrics_data = {
        "Modelo": ["Random Forest", "Logistic Regression"],
        "Precisi√≥n (%)": [95.38, 92.52],
        "AUC": [0.99, 0.99],
        "Recall Maligno (%)": [95.0, 92.0]
    }
    metrics_df = pd.DataFrame(metrics_data)
    st.dataframe(metrics_df)
    st.markdown("""
    - **Accuracy (Precisi√≥n):** Porcentaje de predicciones correctas.
    - **AUC:** Capacidad del modelo para distinguir entre tumores benignos y malignos.
    - **Recall Maligno:** Proporci√≥n de tumores malignos correctamente identificados.
    """)

    # Distribuci√≥n de tumores
    st.subheader("üéóÔ∏è Distribuci√≥n de Tumores")
    fig1, ax1 = plt.subplots()
    sns.countplot(data=df, x="Diagnosis", palette="Purples", ax=ax1)
    ax1.set_title("Distribuci√≥n de Tumores", fontsize=16)
    ax1.set_xlabel("Tipo de Tumor", fontsize=12)
    ax1.set_ylabel("Cantidad", fontsize=12)
    st.pyplot(fig1)

    # Gr√°fico de correlaciones (Mapa de Calor)
    st.subheader("üå°Ô∏è Mapa de Calor de Correlaciones")
    st.markdown("""
    Visualizamos las correlaciones entre caracter√≠sticas del dataset para identificar posibles relaciones y redundancias.
    """)
    fig_corr, ax_corr = plt.subplots(figsize=(12, 8))
    sns.heatmap(df.corr(), annot=False, cmap="Purples", ax=ax_corr)
    ax_corr.set_title("Mapa de Calor de Correlaciones", fontsize=16)
    st.pyplot(fig_corr)

    # Interactividad: Selecci√≥n de caracter√≠sticas
    st.subheader("üîç Exploraci√≥n Interactiva de las Caracter√≠sticas")
    selected_feature_hist = st.selectbox(
        "Selecciona una caracter√≠stica para ver su distribuci√≥n (Histograma):", 
        df.columns.drop("Diagnosis")
    )
    selected_feature_x = st.selectbox(
        "Selecciona la caracter√≠stica X (Gr√°fico de Dispersi√≥n):", 
        df.columns.drop("Diagnosis")
    )
    selected_feature_y = st.selectbox(
        "Selecciona la caracter√≠stica Y (Gr√°fico de Dispersi√≥n):", 
        df.columns.drop("Diagnosis")
    )

    # Histograma interactivo
    st.subheader(f"üìä Distribuci√≥n de `{selected_feature_hist}`")
    fig_hist, ax_hist = plt.subplots()
    sns.histplot(data=df, x=selected_feature_hist, hue="Diagnosis", multiple="stack", palette="Purples", kde=True, ax=ax_hist)
    ax_hist.set_title(f"Distribuci√≥n de `{selected_feature_hist}` por Tipo de Tumor", fontsize=16)
    st.pyplot(fig_hist)

    # Gr√°fico de dispersi√≥n interactivo
    st.subheader(f"üìà Relaci√≥n entre `{selected_feature_x}` y `{selected_feature_y}`")
    fig_scatter, ax_scatter = plt.subplots()
    sns.scatterplot(data=df, x=selected_feature_x, y=selected_feature_y, hue="Diagnosis", palette="coolwarm", ax=ax_scatter)
    ax_scatter.set_title(f"Relaci√≥n entre `{selected_feature_x}` y `{selected_feature_y}`", fontsize=16)
    st.pyplot(fig_scatter)

    # Importancia de las caracter√≠sticas
    st.subheader("üåü Importancia de las Caracter√≠sticas")
    st.markdown("""
    El gr√°fico muestra las 10 caracter√≠sticas m√°s importantes identificadas por el modelo de Bosques Aleatorios. Estas variables influyen significativamente en la predicci√≥n del diagn√≥stico.
    """)

    # Datos de importancia de caracter√≠sticas (aj√∫stalo seg√∫n tu an√°lisis real)
    feature_importances = {
    "Caracter√≠sticas": [
        "Mean_Radius", "Worst_Concavity", "Mean_Concavity", 
        "SE_Radius", "Worst_Compactness", "Mean_Texture", 
        "Mean_Compactness", "Worst_Symmetry", "SE_Concavity", 
        "Worst_Smoothness"
    ],
    "Importancia": [0.202525, 0.170028, 0.134734, 0.087134, 0.069220, 0.049379, 0.049048, 0.031817, 0.028763, 0.024632]
    }

    # Convertir a DataFrame
    importances_df = pd.DataFrame(feature_importances)

    # Crear gr√°fico de barras
    fig_features, ax_features = plt.subplots(figsize=(10, 6))
    sns.barplot(data=importances_df, x="Importancia", y="Caracter√≠sticas", palette="Purples", ax=ax_features)
    ax_features.set_title("Top 10 Caracter√≠sticas M√°s Importantes", fontsize=16)
    ax_features.set_xlabel("Importancia Relativa", fontsize=12)
    ax_features.set_ylabel("Caracter√≠sticas", fontsize=12)
    st.pyplot(fig_features)

    st.markdown("""
    - **Interpretaci√≥n:**  
     Las caracter√≠sticas como `Mean_Radius` y `Worst_Concavity` reflejan propiedades importantes, como tama√±o y forma irregular de los tumores.
    """)

    # üîç Conclusiones del Proyecto
    st.header("üîç Conclusiones del Proyecto")
    st.markdown("""
    El objetivo principal de este proyecto fue desarrollar un modelo predictivo eficaz para clasificar tumores de mama como **benignos** o **malignos**, utilizando datos cl√≠nicos. A continuaci√≥n, detallamos nuestras conclusiones basadas en el proceso completo:

    ### 1Ô∏è‚É£ Elecci√≥n de Random Forest como Mejor Modelo
    Tras probar varios algoritmos de Machine Learning, como:
    - **Random Forest:** Modelo basado en m√∫ltiples √°rboles de decisi√≥n, ideal para identificar patrones complejos.
    - **Logistic Regression:** Un modelo interpretable pero con limitaciones al capturar relaciones no lineales.
    - **Support Vector Machines (SVM):** Potente para relaciones no lineales pero m√°s costoso computacionalmente.

    El **Random Forest** destac√≥ como la mejor opci√≥n, logrando un:
    - **Accuracy:** 95.38%
    - **AUC:** 0.99 (excelente capacidad para diferenciar entre tumores benignos y malignos).
    - **Recall para la clase maligna:** 95.0% (clave para minimizar falsos negativos en el diagn√≥stico).

    ---

    ### 2Ô∏è‚É£ Uso de Validaci√≥n Cruzada (Cross-Validation)
    Para garantizar la robustez y generalizaci√≥n de los modelos, utilizamos **cross-validation** con:
    - **K-Fold:** Dividimos el dataset en 5 pliegues para asegurar que el modelo se eval√∫e con diferentes subconjuntos del dato.
    - **GridSearchCV:** Exploramos diferentes combinaciones de hiperpar√°metros en **Random Forest**, incluyendo:
  - N√∫mero de √°rboles (`n_estimators`): 100
  - M√°xima profundidad (`max_depth`): Sin restricciones
  - Criterio de divisi√≥n (`criterion`): Entrop√≠a

    El uso de cross-validation permiti√≥ identificar la configuraci√≥n √≥ptima del modelo sin sobreajustarlo.

    ---

    ### 3Ô∏è‚É£ Comparaci√≥n con Otras M√©tricas
    Para validar que **Random Forest** era la mejor elecci√≥n, comparamos su desempe√±o frente a otros modelos usando m√©tricas clave:
    - **Accuracy (Precisi√≥n):** Proporci√≥n de predicciones correctas.
    - **AUC (√Årea Bajo la Curva):** Medida de la capacidad del modelo para distinguir entre clases.
    - **Recall Maligno:** Importante para detectar correctamente los tumores malignos y evitar falsos negativos.

    Resultados Comparativos:
    | Modelo               | Accuracy (%) | AUC   | Recall Maligno (%) |
    |----------------------|--------------|-------|--------------------|
    | Random Forest        | 95.38        | 0.99  | 95.0               |
    | Logistic Regression  | 92.52        | 0.99  | 92.0               |
    | Support Vector Machines (SVM) | 93.60 | 0.97  | 93.0               |

    ---

    ### 4Ô∏è‚É£ Interpretaci√≥n de las Caracter√≠sticas Clave
    El modelo de **Random Forest** permiti√≥ identificar las caracter√≠sticas m√°s influyentes:
    - **`Mean_Radius` (Radio Promedio):** Indicador del tama√±o del tumor.
    - **`Worst_Concavity` (Mayor Concavidad):** Refleja la irregularidad en los bordes del tumor.
    - **`Mean_Concavity` (Concavidad Promedio):** Complementa la detecci√≥n de formas irregulares.

    Estas caracter√≠sticas son fundamentales para diferenciar entre tumores benignos y malignos.

    ---

    ### 5Ô∏è‚É£ Importancia del Machine Learning en la Medicina
    Este proyecto demuestra c√≥mo el uso de **Machine Learning** puede complementar el juicio m√©dico en el diagn√≥stico temprano de enfermedades cr√≠ticas como el c√°ncer de mama. Aunque este trabajo es acad√©mico y no debe reemplazar evaluaciones m√©dicas, destaca el valor de integrar tecnolog√≠a avanzada en la salud.

    üíñ **Gracias por explorar este proyecto!** Sigamos trabajando en soluciones tecnol√≥gicas que marquen la diferencia.
    """)

# ü§ñ Pantalla 3: Predicciones Interactivas
elif page == "Predicciones Interactivas":
    st.title("ü§ñ Predicciones Interactivas")
    st.markdown("""
    En esta p√°gina puedes ingresar valores de ciertas caracter√≠sticas del tumor 
    para obtener una **predicci√≥n simulada** de si el tumor es **benigno** o **maligno**.  
    **Nota:** Esta funcionalidad es educativa y no debe usarse con fines m√©dicos.
    """)

    # Entrada de datos por parte del usuario
    input_data = {}
    for feature in ["Mean_Radius", "Mean_Concavity", "Worst_Concavity"]:
        input_data[feature] = st.number_input(
            f"Ingrese el valor para {feature}:",
            min_value=0.0,
            step=0.1
        )

    # Bot√≥n de predicci√≥n
    if st.button("Predecir"):
        # Simulaci√≥n de predicci√≥n usando el valor de Mean_Radius
        prediction = "Maligno" if input_data["Mean_Radius"] > 15 else "Benigno"
        
        # Mostrar el resultado de la predicci√≥n
        st.success(f"El modelo predice que el tumor es: **{prediction}**")
        st.info("Este resultado es una simulaci√≥n y en ning√∫n momento representa un diagn√≥stico m√©dico real.")
