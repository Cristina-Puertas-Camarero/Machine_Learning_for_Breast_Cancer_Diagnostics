{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Modelado Predictivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Key backend: 'module://matplotlib_inline.backend_inline' is not a valid value for backend; supported values are ['gtk3agg', 'gtk3cairo', 'gtk4agg', 'gtk4cairo', 'macosx', 'nbagg', 'notebook', 'qtagg', 'qtcairo', 'qt5agg', 'qt5cairo', 'tkagg', 'tkcairo', 'webagg', 'wx', 'wxagg', 'wxcairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\__init__.py:1296\u001b[0m\n\u001b[0;32m   1292\u001b[0m     rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend_fallback\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMPLBACKEND\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m-> 1296\u001b[0m     \u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMPLBACKEND\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_backend\u001b[39m(\u001b[38;5;241m*\u001b[39m, auto_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m    Return the name of the current backend.\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;124;03m    matplotlib.use\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\matplotlib\\__init__.py:771\u001b[0m, in \u001b[0;36mRcParams.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m    769\u001b[0m         cval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate[key](val)\n\u001b[0;32m    770\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ve:\n\u001b[1;32m--> 771\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mve\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set(key, cval)\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: Key backend: 'module://matplotlib_inline.backend_inline' is not a valid value for backend; supported values are ['gtk3agg', 'gtk3cairo', 'gtk4agg', 'gtk4cairo', 'macosx', 'nbagg', 'notebook', 'qtagg', 'qtcairo', 'qt5agg', 'qt5cairo', 'tkagg', 'tkcairo', 'webagg', 'wx', 'wxagg', 'wxcairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']"
     ]
    }
   ],
   "source": [
    "# importamos todas las librerias necesarias\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure plots are displayed inline in the notebook\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('png', 'pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos el dataset limpio\n",
    "df = pd.read_csv('datos/4_dataset_sin_correlaciones_altas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado Predictivo\n",
    "\n",
    "### Paso 1: División del Dataset\n",
    "Antes de entrenar cualquier modelo, dividiremos el dataset en conjuntos de entrenamiento y prueba. Esto nos permitirá evaluar el rendimiento de los modelos en datos no vistos.\n",
    "\n",
    "### Paso 2: Entrenamiento de Modelos Iniciales\n",
    "Entrenaremos los modelos iniciales:\n",
    "\n",
    "Regresión Logística.\n",
    "\n",
    "Bosques Aleatorios.\n",
    "\n",
    "SVM (Máquinas de Soporte Vectorial).\n",
    "\n",
    "### Paso 3: Evaluación del Desempeño\n",
    "Usaremos métricas como:\n",
    "\n",
    "Accuracy (precisión general).\n",
    "\n",
    "Recall (muy importante en problemas médicos, ya que queremos minimizar falsos negativos).\n",
    "\n",
    "F1-Score (un balance entre Precision y Recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos de entrenamiento: (455, 20), Datos de prueba: (114, 20)\n",
      "\n",
      "Rendimiento del modelo: Regresión Logística\n",
      "Accuracy: 0.96\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97        71\n",
      "           1       0.95      0.93      0.94        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "Rendimiento del modelo: Bosques Aleatorios\n",
      "Accuracy: 0.96\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        71\n",
      "           1       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "Rendimiento del modelo: SVM\n",
      "Accuracy: 0.91\n",
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        71\n",
      "           1       0.92      0.84      0.88        43\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.90      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías para modelado\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Paso 1: Dividir el dataset en entrenamiento y prueba\n",
    "# Separar las características (X) de la variable objetivo (y)\n",
    "X = df.drop(columns=\"Diagnosis\")\n",
    "y = df[\"Diagnosis\"]\n",
    "\n",
    "# División en entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Datos de entrenamiento: {X_train.shape}, Datos de prueba: {X_test.shape}\")\n",
    "\n",
    "# Paso 2: Entrenar los modelos iniciales\n",
    "# Regresión Logística\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Bosques Aleatorios\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Paso 3: Evaluar los modelos\n",
    "models = {\n",
    "    \"Regresión Logística\": log_reg,\n",
    "    \"Bosques Aleatorios\": rf,\n",
    "    \"SVM\": svm\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Predicciones en el conjunto de prueba\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\nRendimiento del modelo: {name}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "    print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis por Modelo\n",
    "\n",
    "1. Regresión Logística:\n",
    "Accuracy: 96%.\n",
    "\n",
    "Precision y Recall (Clases 0 y 1): Altos y bien equilibrados:\n",
    "\n",
    "Para la clase 0 (benigno): 96% precision, 97% recall.\n",
    "\n",
    "Para la clase 1 (maligno): 95% precision, 93% recall.\n",
    "\n",
    "F1-Score: También equilibrado con 0.97 para benignos y 0.94 para malignos.\n",
    "\n",
    "Conclusión: La Regresión Logística tiene un rendimiento sólido y balanceado. Es un modelo interpretable, lo que puede ser útil en contextos médicos.\n",
    "\n",
    "2. Bosques Aleatorios:\n",
    "Accuracy: 96% (idéntico a la Regresión Logística).\n",
    "\n",
    "Precision y Recall:\n",
    "\n",
    "Clase 0 (benigno): 97% precision, 97% recall.\n",
    "\n",
    "Clase 1 (maligno): 95% precision, 95% recall.\n",
    "\n",
    "F1-Score: Equilibrado con 0.97 (benignos) y 0.95 (malignos).\n",
    "\n",
    "Conclusión: Los Bosques Aleatorios también tienen un rendimiento excepcional. Además, este modelo ofrece interpretabilidad en términos de importancia de características, lo que puede ser útil para identificar los factores clave en el diagnóstico.\n",
    "\n",
    "3. SVM (Máquinas de Soporte Vectorial):\n",
    "Accuracy: 91% (inferior a los otros dos modelos).\n",
    "\n",
    "Precision y Recall:\n",
    "\n",
    "Clase 0 (benigno): 91% precision, 96% recall.\n",
    "\n",
    "Clase 1 (maligno): 92% precision, 84% recall.\n",
    "\n",
    "F1-Score: 0.93 para benignos y 0.88 para malignos.\n",
    "\n",
    "Conclusión: Aunque la SVM es potente en términos de manejo de relaciones complejas, aquí tiene un menor rendimiento, especialmente en el recall para la clase maligno (84%). Esto es preocupante en el contexto médico, ya que queremos minimizar falsos negativos.\n",
    "\n",
    "Resumen Comparativo\n",
    "Modelo\tAccuracy\tPrecision (Clase 1)\tRecall (Clase 1)\tF1-Score (Clase 1)\n",
    "Regresión Logística\t96%\t95%\t93%\t94%\n",
    "Bosques Aleatorios\t96%\t95%\t95%\t95%\n",
    "SVM\t91%\t92%\t84%\t88%\n",
    "Conclusión Inicial\n",
    "Mejor Modelo: Bosques Aleatorios\n",
    "\n",
    "¿Por qué? Aunque su accuracy es similar al de la Regresión Logística, tiene un recall más alto en la clase maligno (95% frente a 93%), lo cual es crucial en este contexto para evitar falsos negativos.\n",
    "\n",
    "Modelo Secundario: Regresión Logística\n",
    "\n",
    "¿Por qué? Ofrece métricas muy similares a las de Bosques Aleatorios, con un rendimiento sólido y excelente interpretabilidad.\n",
    "\n",
    "Modelo con Menor Desempeño: SVM\n",
    "\n",
    "¿Por qué? Su menor recall para la clase maligno (84%) lo hace menos confiable en un problema donde detectar tumores malignos es prioritario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
